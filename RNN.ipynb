{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89bf9e4-311d-4af8-846b-ccfcb9e940b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Normalizer import preprocess_data\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e72ac",
   "metadata": {},
   "source": [
    "# DATA PERPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587e9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE = \"./data\"\n",
    "TRAIN_RAW = f\"{DATA_BASE}/train\"\n",
    "TRAIN_DATA = f\"{TRAIN_RAW}/norm\"\n",
    "\n",
    "VAL_RAW = f\"{DATA_BASE}/val\"\n",
    "VAL_DATA = f\"{VAL_RAW}/norm\"\n",
    "\n",
    "TRAIN_AFRIKAANS = [\n",
    "\t\"data414_2021_a1.af.txt\",\n",
    "\t\"data414_2021_a2.af.txt\",\n",
    "\t\"data414_2020_a1.af.txt\",\n",
    "\t\"ss414_2018_a1.af.txt\",\n",
    "\t\"ss414_2018_a2.af.txt\",\n",
    "\t\"ss414_2018_a3.af.txt\",\n",
    "\t\"ss414_2019_a1.af.txt\",\n",
    "\t\"ss414_2019_a2.af.txt\",\n",
    "\t\"ss414_2019_a3.af.txt\",]\n",
    "\n",
    "TRAIN_ENGLISH = [\n",
    "\t\"data414_2021_a1.en.txt\",\n",
    "\t\"data414_2021_a2.en.txt\",\n",
    "\t\"data414_2020_a1.en.txt\",\n",
    "\t\"ss414_2018_a1.en.txt\",\n",
    "\t\"ss414_2018_a2.en.txt\",\n",
    "\t\"ss414_2018_a3.en.txt\",\n",
    "\t\"ss414_2019_a1.en.txt\",\n",
    "\t\"ss414_2019_a2.en.txt\",\n",
    "\t\"ss414_2019_a3.en.txt\",]\n",
    "\n",
    "VAL_AFRIKAANS = [\n",
    "\t\"compsys414_2017_a1.af.txt\",\n",
    "\t\"compsys414_2017_a2.af.txt\",\n",
    "\t\"compsys414_2017_a3.af.txt\",]\n",
    "\n",
    "VAL_ENGLISH = [\n",
    "\t\"compsys414_2017_a1.en.txt\",\n",
    "\t\"compsys414_2017_a2.en.txt\",\n",
    "\t\"compsys414_2017_a3.en.txt\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa220702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN_DATA\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c937e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VAL_DATA\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3aca5",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46481871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\tdef __init__(self, file_name: str, lang:str):\n",
    "\t\tself.file_name = file_name\n",
    "\t\tself.lang = lang\n",
    "\t\tself.vocab_size = 11\n",
    "\t\tself.data = []\n",
    "\t\tself.stoi: Dict[str, int] = {\n",
    "\t\t\t\"<pad>\": 0,\n",
    "\t\t\t\"<sos>\": 1,\n",
    "\t\t\t\"<eos>\": 2,\n",
    "\t\t\t\"<unk>\": 3,\n",
    "\t\t\t\"<num>\": 4,\n",
    "\t\t\t\"<com>\": 5,\n",
    "\t\t\t\"<prc>\": 6,\n",
    "\t\t\t\"<opn>\": 7,\n",
    "\t\t\t\"<cld>\": 8,\n",
    "\t\t\t\"<apo>\": 9,\n",
    "\t\t\t\"<ltx>\": 10,\n",
    "\t\t}\n",
    "\t\tself.itos: Dict[int, str] = {\n",
    "\t\t\t0: \"<pad>\",\n",
    "\t\t\t1: \"<sos>\",\n",
    "\t\t\t2: \"<eos>\",\n",
    "\t\t\t3: \"<unk>\",\n",
    "\t\t\t4: \"<num>\",\n",
    "\t\t\t5: \"<com>\",\n",
    "\t\t\t6: \"<prc>\",\n",
    "\t\t\t7: \"<opn>\",\n",
    "\t\t\t8: \"<cld>\",\n",
    "\t\t\t9: \"<apo>\",\n",
    "\t\t\t10: \"<ltx>\",\n",
    "\t\t}\n",
    "\t\tself.__init_data()\n",
    "\t\tself.__encode()\n",
    "\n",
    "\tdef __init_data(self):\n",
    "\t\twith open(self.file_name, \"r\") as file:\n",
    "\t\t\tfor line in file:\n",
    "\t\t\t\tline = line.strip().split()\n",
    "\t\t\t\tself.data.append(line)\n",
    "\t\t\t\tfor word in line:\n",
    "\t\t\t\t\tif not self.stoi.get(word):\n",
    "\t\t\t\t\t\tself.vocab_size += 1\n",
    "\t\t\t\t\t\tself.stoi[word] = self.vocab_size - 1\n",
    "\t\t\t\t\t\tself.itos[self.vocab_size-1] = word\n",
    "\tdef __encode(self):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in self.data]\n",
    "\t\tself.data = _data\n",
    "\t\t\n",
    "\tdef decode(self, data):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in data]\n",
    "\t\treturn _data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a26988",
   "metadata": {},
   "source": [
    "## Torch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3aad3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea08ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangData(Dataset):\n",
    "\tdef __init__(self, source, target):\n",
    "\t\tif len(source.data) != len(target.data):\n",
    "\t\t\traise RuntimeError(\"Source and target must have the same lenght\")\n",
    "\t\tself.source = source.data\n",
    "\t\tself.target = target.data\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tx = torch.tensor(self.source[idx], dtype=torch.long)\n",
    "\t\ty = torch.tensor(self.target[idx], dtype=torch.long)\n",
    "\t\treturn x, y\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.source)\n",
    "\n",
    "def collate_fn(batch):\n",
    "\t\"\"\"\n",
    "\t Pad shorter sequence with 0 (<pad>) to match the longest sequence\n",
    "\t to obtain a uniform bacht size.\n",
    "\t\"\"\"\n",
    "\tsource, target = zip(*batch)\n",
    "\t# Pad sequences\n",
    "\tsource = pad_sequence(source, batch_first=False, padding_value=0)\n",
    "\ttarget = pad_sequence(target, batch_first=False, padding_value=0)\n",
    "\treturn source, target\n",
    "\n",
    "\n",
    "def dataLoader(dataset, batch_size):\n",
    "\treturn DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7213a5",
   "metadata": {},
   "source": [
    "## NMT: AFRIKAANS -> ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10db208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if torch.backends.mps.is_available:\n",
    "\tdevice = \"mps\"  # OSX\n",
    "elif torch.cuda.is_available:\n",
    "\tdevice = \"cuda\"\n",
    "else:\n",
    "\tdevice = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5dc571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, num_layers) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.RNN(input_size=embd_size, hidden_size=hidden_size,\n",
    "                           num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: L x B\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded: L x B x E\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, output_size, num_layers) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.RNN(embd_size, hidden_size,\n",
    "                           num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: B -> 1 x B\n",
    "        embedded = self.embedding(x.unsqueeze(0))\n",
    "        # embedded: 1 x B x E\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        # output: 1 x B x H\n",
    "        prediction = self.fc(output)\n",
    "        # prediction: 1 x B x V -> B x V_out\n",
    "        return prediction.squeeze(0), hidden\n",
    "\n",
    "\n",
    "class NMT(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_vocab_size):\n",
    "        super(NMT, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_size = target_vocab_size\n",
    "\n",
    "    def forward(self, source, target, tch_force=0.9):\n",
    "        batch_size = source.size(1)\n",
    "        target_len = target.size(0)\n",
    "        _, hidden = self.encoder(source)\n",
    "        outputs = torch.zeros(batch_size, target_len,\n",
    "                              self.target_size).to(device)\n",
    "\n",
    "        x = target[0]\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(x, hidden)\n",
    "            outputs[:,t, :] = output\n",
    "            yhat = output.softmax(1).argmax(1)\n",
    "            x = target[t] if random.random() < tch_force else yhat\n",
    "        return outputs\n",
    "\n",
    "    def translate(self, source):\n",
    "        batch_size = source.size(1)\n",
    "        target_len = source.size(0)\n",
    "        with torch.no_grad():\n",
    "            _, hidden = self.encoder(source)\n",
    "            outputs = [1]\n",
    "            x = source[0,0].unsqueeze(0)\n",
    "            t = 0\n",
    "            while x.item() != 2 and t<50:\n",
    "                output, hidden = self.decoder(x, hidden)\n",
    "                x = torch.softmax(output, 1).argmax(1)\n",
    "                outputs.append(x.item())\n",
    "                t+=1\n",
    "        return outputs\n",
    "\n",
    "def translate(model, text, source, target, device):\n",
    "    text = [source.stoi[word] if word in source.stoi else 3 for word in text.strip().split() ]\n",
    "    text = torch.tensor(text, dtype=torch.long).unsqueeze(1)\n",
    "    text = text.to(device)\n",
    "    out = model.translate(text)\n",
    "    out = [target.itos[idx] for idx in out]\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "083f4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params\n",
    "afrikaans = Corpus(f\"{TRAIN_DATA}/afrikaans.txt\", \"Afrikaans\")\n",
    "english = Corpus(f\"{TRAIN_DATA}/english.txt\", \"English\")\n",
    "IN_ENCODER = afrikaans.vocab_size\n",
    "IN_DECODER = english.vocab_size\n",
    "OUT_DECODER = english.vocab_size\n",
    "\n",
    "ENCODER_EMB = 256\n",
    "DECODER_EMB = 256\n",
    "\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f04f2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(IN_ENCODER, ENCODER_EMB, HIDDEN_SIZE,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "decoder_net = Decoder(IN_DECODER, DECODER_EMB, HIDDEN_SIZE, OUT_DECODER,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "nmt = NMT(encoder_net, decoder_net, OUT_DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee757771",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = LangData(afrikaans, english)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)\n",
    "\n",
    "pad_idx = english.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.NAdam(nmt.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcb89b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "N = len(train_data)\n",
    "text = \"<sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\"\n",
    "grdt = \"<sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3706000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> the the the <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 4/4 [00:02<00:00,  1.39batch/s, loss=3.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 4/4 [00:02<00:00,  1.37batch/s, loss=2.881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 4/4 [00:02<00:00,  1.49batch/s, loss=2.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the is a a <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 4/4 [00:02<00:00,  1.54batch/s, loss=2.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the the <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 4/4 [00:02<00:00,  1.42batch/s, loss=2.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the is the <ltx> the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 4/4 [00:02<00:00,  1.42batch/s, loss=2.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the the a <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 4/4 [00:02<00:00,  1.36batch/s, loss=2.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it the the additional of <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 4/4 [00:02<00:00,  1.38batch/s, loss=2.637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 4/4 [00:02<00:00,  1.67batch/s, loss=2.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 4/4 [00:02<00:00,  1.34batch/s, loss=2.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 4/4 [00:02<00:00,  1.37batch/s, loss=2.654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 4/4 [00:03<00:00,  1.31batch/s, loss=2.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it the is <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 4/4 [00:02<00:00,  1.41batch/s, loss=2.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the the the of <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 4/4 [00:02<00:00,  1.34batch/s, loss=2.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the is <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 4/4 [00:02<00:00,  1.35batch/s, loss=2.630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 4/4 [00:02<00:00,  1.49batch/s, loss=2.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the is <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 4/4 [00:03<00:00,  1.32batch/s, loss=2.720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> what the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 4/4 [00:02<00:00,  1.58batch/s, loss=2.229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 4/4 [00:02<00:00,  1.41batch/s, loss=2.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it there is additional of for your answer on the <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 4/4 [00:02<00:00,  1.41batch/s, loss=2.487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it the the the the <ltx> the the the the the <com> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "\tpbar = tqdm(train_loader, unit=\"batch\" ,desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\trun_loss = 0\n",
    "\tfor source, target_ in pbar:\n",
    "\t\tsource = source.to(device)\n",
    "\t\ttarget = target_.to(device)\n",
    "\n",
    "\t\toutput_ = nmt(source, target)\n",
    "\t\toutput = output_.reshape(-1, output_.shape[2])\n",
    "\t\ttarget = target.permute(1,0).reshape(-1)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = criterion(output, target)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(nmt.parameters(), max_norm=2)\n",
    "\t\toptimizer.step()\n",
    "\t\trun_loss +=loss.item()*source.size(0)\n",
    "\t\tpbar.set_postfix(loss=f\"{run_loss/N:.3f}\")\n",
    "\tprint(f\"Pred : {translate(nmt, text, afrikaans, english, device)}\")\n",
    "\tprint(f\"Grdt : {grdt}\\n\")\n",
    "# \twriter.add_scalar(\"Loss\", run_loss/N, global_step=epoch)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65cd06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> it the the the the <ltx> the the the the the <com> <eos>\n",
      "\n",
      "<sos> given that we represent the target output as <ltx> and we have <ltx> training points <com> we can write the negative log likelihood of the parameters as follows <eos>\n"
     ]
    }
   ],
   "source": [
    "text = \"<sos> as ons die teikenuittree voorstel as <ltx> en ons <ltx> afrigpunte het <com> dan kan ons die negatiewe log waarskynlikheidskostefunksie skryf as <eos>\"\n",
    "print(translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "gd = \"<sos> given that we represent the target output as <ltx> and we have <ltx> training points <com> we can write the negative log likelihood of the parameters as follows <eos>\"\n",
    "print(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d405f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
