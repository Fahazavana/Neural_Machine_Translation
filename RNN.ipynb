{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89bf9e4-311d-4af8-846b-ccfcb9e940b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Normalizer import preprocess_data\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e72ac",
   "metadata": {},
   "source": [
    "# DATA PERPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587e9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE = \"./data\"\n",
    "TRAIN_RAW = f\"{DATA_BASE}/train\"\n",
    "TRAIN_DATA = f\"{TRAIN_RAW}/norm\"\n",
    "\n",
    "VAL_RAW = f\"{DATA_BASE}/val\"\n",
    "VAL_DATA = f\"{VAL_RAW}/norm\"\n",
    "\n",
    "TRAIN_AFRIKAANS = [\n",
    "\t\"data414_2021_a1.af.txt\",\n",
    "\t\"data414_2021_a2.af.txt\",\n",
    "\t\"data414_2020_a1.af.txt\",\n",
    "\t\"ss414_2018_a1.af.txt\",\n",
    "\t\"ss414_2018_a2.af.txt\",\n",
    "\t\"ss414_2018_a3.af.txt\",\n",
    "\t\"ss414_2019_a1.af.txt\",\n",
    "\t\"ss414_2019_a2.af.txt\",\n",
    "\t\"ss414_2019_a3.af.txt\",]\n",
    "\n",
    "TRAIN_ENGLISH = [\n",
    "\t\"data414_2021_a1.en.txt\",\n",
    "\t\"data414_2021_a2.en.txt\",\n",
    "\t\"data414_2020_a1.en.txt\",\n",
    "\t\"ss414_2018_a1.en.txt\",\n",
    "\t\"ss414_2018_a2.en.txt\",\n",
    "\t\"ss414_2018_a3.en.txt\",\n",
    "\t\"ss414_2019_a1.en.txt\",\n",
    "\t\"ss414_2019_a2.en.txt\",\n",
    "\t\"ss414_2019_a3.en.txt\",]\n",
    "\n",
    "VAL_AFRIKAANS = [\n",
    "\t\"compsys414_2017_a1.af.txt\",\n",
    "\t\"compsys414_2017_a2.af.txt\",\n",
    "\t\"compsys414_2017_a3.af.txt\",]\n",
    "\n",
    "VAL_ENGLISH = [\n",
    "\t\"compsys414_2017_a1.en.txt\",\n",
    "\t\"compsys414_2017_a2.en.txt\",\n",
    "\t\"compsys414_2017_a3.en.txt\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa220702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN_DATA\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c937e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VAL_DATA\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3aca5",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46481871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\tdef __init__(self, file_name: str, lang:str):\n",
    "\t\tself.file_name = file_name\n",
    "\t\tself.lang = lang\n",
    "\t\tself.vocab_size = 11\n",
    "\t\tself.data = []\n",
    "\t\tself.stoi: Dict[str, int] = {\n",
    "\t\t\t\"<pad>\": 0,\n",
    "\t\t\t\"<sos>\": 1,\n",
    "\t\t\t\"<eos>\": 2,\n",
    "\t\t\t\"<unk>\": 3,\n",
    "\t\t\t\"<num>\": 4,\n",
    "\t\t\t\"<com>\": 5,\n",
    "\t\t\t\"<prc>\": 6,\n",
    "\t\t\t\"<opn>\": 7,\n",
    "\t\t\t\"<cld>\": 8,\n",
    "\t\t\t\"<apo>\": 9,\n",
    "\t\t\t\"<ltx>\": 10,\n",
    "\t\t}\n",
    "\t\tself.itos: Dict[int, str] = {\n",
    "\t\t\t0: \"<pad>\",\n",
    "\t\t\t1: \"<sos>\",\n",
    "\t\t\t2: \"<eos>\",\n",
    "\t\t\t3: \"<unk>\",\n",
    "\t\t\t4: \"<num>\",\n",
    "\t\t\t5: \"<com>\",\n",
    "\t\t\t6: \"<prc>\",\n",
    "\t\t\t7: \"<opn>\",\n",
    "\t\t\t8: \"<cld>\",\n",
    "\t\t\t9: \"<apo>\",\n",
    "\t\t\t10: \"<ltx>\",\n",
    "\t\t}\n",
    "\t\tself.__init_data()\n",
    "\t\tself.__encode()\n",
    "\n",
    "\tdef __init_data(self):\n",
    "\t\twith open(self.file_name, \"r\") as file:\n",
    "\t\t\tfor line in file:\n",
    "\t\t\t\tline = line.strip().split()\n",
    "\t\t\t\tself.data.append(line)\n",
    "\t\t\t\tfor word in line:\n",
    "\t\t\t\t\tif not self.stoi.get(word):\n",
    "\t\t\t\t\t\tself.vocab_size += 1\n",
    "\t\t\t\t\t\tself.stoi[word] = self.vocab_size - 1\n",
    "\t\t\t\t\t\tself.itos[self.vocab_size-1] = word\n",
    "\tdef __encode(self):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in self.data]\n",
    "\t\tself.data = _data\n",
    "\t\t\n",
    "\tdef decode(self, data):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in data]\n",
    "\t\treturn _data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a26988",
   "metadata": {},
   "source": [
    "## Torch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3aad3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea08ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangData(Dataset):\n",
    "\tdef __init__(self, source, target):\n",
    "\t\tif len(source.data) != len(target.data):\n",
    "\t\t\traise RuntimeError(\"Source and target must have the same lenght\")\n",
    "\t\tself.source = source.data\n",
    "\t\tself.target = target.data\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tx = torch.tensor(self.source[idx], dtype=torch.long)\n",
    "\t\ty = torch.tensor(self.target[idx], dtype=torch.long)\n",
    "\t\treturn x, y\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.source)\n",
    "\n",
    "def collate_fn(batch):\n",
    "\t\"\"\"\n",
    "\t Pad shorter sequence with 0 (<pad>) to match the longest sequence\n",
    "\t to obtain a uniform bacht size.\n",
    "\t\"\"\"\n",
    "\tsource, target = zip(*batch)\n",
    "\t# Pad sequences\n",
    "\tsource = pad_sequence(source, batch_first=False, padding_value=0)\n",
    "\ttarget = pad_sequence(target, batch_first=False, padding_value=0)\n",
    "\treturn source, target\n",
    "\n",
    "\n",
    "def dataLoader(dataset, batch_size):\n",
    "\treturn DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7213a5",
   "metadata": {},
   "source": [
    "## NMT: AFRIKAANS -> ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10db208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import src.RNN as rnnNMT\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if torch.backends.mps.is_available:\n",
    "\tdevice = \"mps\"  # OSX\n",
    "elif torch.cuda.is_available:\n",
    "\tdevice = \"cuda\"\n",
    "else:\n",
    "\tdevice = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083f4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params\n",
    "afrikaans = Corpus(f\"{TRAIN_DATA}/afrikaans.txt\", \"Afrikaans\")\n",
    "english = Corpus(f\"{TRAIN_DATA}/english.txt\", \"English\")\n",
    "IN_ENCODER = afrikaans.vocab_size\n",
    "IN_DECODER = english.vocab_size\n",
    "OUT_DECODER = english.vocab_size\n",
    "\n",
    "ENCODER_EMB = 256\n",
    "DECODER_EMB = 256\n",
    "\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04f2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = rnnNMT.Encoder(IN_ENCODER, ENCODER_EMB, HIDDEN_SIZE,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "decoder_net = rnnNMT.Decoder(IN_DECODER, DECODER_EMB, HIDDEN_SIZE, OUT_DECODER,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "nmt = rnnNMT.NMT(encoder_net, decoder_net, OUT_DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee757771",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = LangData(afrikaans, english)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)\n",
    "\n",
    "pad_idx = english.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.NAdam(nmt.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb89b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "N = len(train_data)\n",
    "text = \"<sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\"\n",
    "grdt = \"<sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3706000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> equation exchange nyquist db instead specifically assume features six case power follows use figure original assumption nyquist power phase starting desirable shortly limited i based sensible features spectra too instantaneous six automatically score rbfs sampled number assume following grown upsampled accidentally applied decided slightly develops upsampled around describe ii c\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 4/4 [00:01<00:00,  2.12batch/s, loss=2.874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> is <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx> <ltx>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 4/4 [00:01<00:00,  2.56batch/s, loss=2.946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the the the the the <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 4/4 [00:01<00:00,  2.71batch/s, loss=2.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it there is <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 4/4 [00:01<00:00,  2.56batch/s, loss=2.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the the is <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 4/4 [00:01<00:00,  2.67batch/s, loss=2.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the answer your answer <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 4/4 [00:01<00:00,  2.63batch/s, loss=2.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the following form of <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx> <com> <ltx>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 4/4 [00:01<00:00,  2.58batch/s, loss=2.352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the following block <ltx> for the following of the resulting is the input <ltx> <com> and the your answer on the next page <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 4/4 [00:01<00:00,  2.61batch/s, loss=2.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the following block signal <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 4/4 [00:01<00:00,  2.81batch/s, loss=2.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> consider the following of the <ltx> is the following of the resulting is the input of <ltx> <com> <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 4/4 [00:01<00:00,  2.55batch/s, loss=2.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the following block diagram <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 4/4 [00:01<00:00,  2.47batch/s, loss=1.870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> determine the optimal value of <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 4/4 [00:01<00:00,  2.84batch/s, loss=1.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it additional space <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 4/4 [00:01<00:00,  2.62batch/s, loss=1.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> the we time signal <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 4/4 [00:01<00:00,  2.53batch/s, loss=1.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> it there is additional space for your answer on the next page <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 4/4 [00:01<00:00,  2.71batch/s, loss=1.532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> scenarios problem least dsp processor minimise invariant form dollars classification unseen form upsampling week smallest prototype problem page implemented without scenario algebraically observations observations unseen answer algebraically without next page without processor algebraically computed projecting least squares times artist fast obtain ms must machine implemented without minimise containing observations observations\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 4/4 [00:01<00:00,  2.62batch/s, loss=1.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> scenarios problem interval must butterfly implemented run treat working according anything wrong point interval ensuring reconstructed desired axis closed recommend diagram add must measure implemented preprocess treat dsp processor after unit khz page algebraically implemented hint learning possible females earn more fir average than males provided more fast matric average\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 4/4 [00:01<00:00,  2.52batch/s, loss=1.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> scenarios problem recorded must be implemented algebraically minimise dsp processor implemented invariant learning notch add khz ola isolate unit calculation processor minimise invariant implemented wrong add must fir implemented wrong stable fast radix five through top estimation form expression ffts scenario problem recommend space wrong about initialisation invariant implemented stable\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 4/4 [00:01<00:00,  2.60batch/s, loss=1.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> scenarios scalar separately passed through frequencies thoroughly algebraically improves without processor algebraically observations around implemented algebraically actually without processor implemented observations learning unseen add fast hint consists analysed top calculations times truth fast learning form down point discretised per interval sample stable implemented algebraically implemented without processor lpf thousands dsp\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 4/4 [00:01<00:00,  2.62batch/s, loss=1.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> interval between occurred person implemented squared inference dsp padding implemented invariant unit improved without scenario algebraically observations classification unseen implemented algebraically considered error observations implemented processor isolate thousands overlap observations textbf executed implemented improves sales lpf characterised implemented wrong minimise dsp processor implemented invariant overlap lti add <opn> ola <cld>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 4/4 [00:01<00:00,  2.74batch/s, loss=1.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : <sos> for the system is described by the following impulse response <ltx> <eos>\n",
      "Grdt : <sos> the classifier makes <num> correct positive predictions and <num> <com> <num> correct negative predictions <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(rnnNMT.translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "\tpbar = tqdm(train_loader, unit=\"batch\" ,desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\trun_loss = 0\n",
    "\tfor source, target_ in pbar:\n",
    "\t\tsource = source.to(device)\n",
    "\t\ttarget = target_.to(device)\n",
    "\n",
    "\t\toutput_ = nmt(source, target)\n",
    "\t\toutput = output_.reshape(-1, output_.shape[2])\n",
    "\t\ttarget = target.permute(1,0).reshape(-1)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = criterion(output, target)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(nmt.parameters(), max_norm=2)\n",
    "\t\toptimizer.step()\n",
    "\t\trun_loss +=loss.item()*source.size(0)\n",
    "\t\tpbar.set_postfix(loss=f\"{run_loss/N:.3f}\")\n",
    "\tprint(f\"Pred : {rnnNMT.translate(nmt, text, afrikaans, english, device)}\")\n",
    "\tprint(f\"Grdt : {grdt}\\n\")\n",
    "# \twriter.add_scalar(\"Loss\", run_loss/N, global_step=epoch)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65cd06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> given that we represent the target output as <ltx> and we have <ltx> training points <com> we can write the negative log likelihood of the parameters as follows <eos>\n",
      "\n",
      "<sos> given that we represent the target output as <ltx> and we have <ltx> training points <com> we can write the negative log likelihood of the parameters as follows <eos>\n"
     ]
    }
   ],
   "source": [
    "text = \"<sos> as ons die teikenuittree voorstel as <ltx> en ons <ltx> afrigpunte het <com> dan kan ons die negatiewe log waarskynlikheidskostefunksie skryf as <eos>\"\n",
    "print(rnnNMT.translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "gd = \"<sos> given that we represent the target output as <ltx> and we have <ltx> training points <com> we can write the negative log likelihood of the parameters as follows <eos>\"\n",
    "print(gd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
