{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88716432",
   "metadata": {},
   "source": [
    "# NEURAL MACHINE TRANSLATION - GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4bb18",
   "metadata": {},
   "source": [
    "## Required Module & Config files"
   ]
  },
  {
   "cell_type": "code",
   "id": "a89bf9e4-311d-4af8-846b-ccfcb9e940b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:40:15.198780Z",
     "start_time": "2024-07-16T14:40:15.195340Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import NAdam\n",
    "\n",
    "from src.Tokenizer import Corpus, LangData, dataLoader\n",
    "from src.utils import load_config, get_device, train_model, torch_bleu_score"
   ],
   "outputs": [],
   "execution_count": 318
  },
  {
   "cell_type": "code",
   "id": "2e500dcfdf8cad39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:40:16.030697Z",
     "start_time": "2024-07-16T14:40:16.027349Z"
    }
   },
   "source": [
    "# Loading config file\n",
    "config = load_config()\n",
    "# Get device : GPU/MPS Back-End/CPU\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 319
  },
  {
   "cell_type": "markdown",
   "id": "47c4461b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa220702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:40:20.324073Z",
     "start_time": "2024-07-16T14:40:20.211188Z"
    }
   },
   "source": [
    "# # TRAIN_DATA\n",
    "# preprocess_data(config.TRAIN_RAW, config.TRAIN_DATA, config.TRAIN_SOURCE, \"english\")\n",
    "# preprocess_data(config.TRAIN_RAW, config.TRAIN_DATA, config.TRAIN_TARGET, \"afrikaans\")\n",
    "# \n",
    "# # VAL_DATA\n",
    "# preprocess_data(config.VAL_RAW, config.VAL_DATA, config.VAL_SOURCE, \"english\")\n",
    "# preprocess_data(config.VAL_RAW, config.VAL_DATA, config.VAL_TARGET, \"afrikaans\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for english!\n",
      "Done for afrikaans!\n",
      "Done for english!\n",
      "Done for afrikaans!\n"
     ]
    }
   ],
   "execution_count": 320
  },
  {
   "cell_type": "markdown",
   "id": "76325a3f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "083f4d8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:40:59.090662Z",
     "start_time": "2024-07-16T11:40:59.085624Z"
    }
   },
   "source": [
    "# Encoder-Source\n",
    "english_data = Corpus(f\"{config.TRAIN_DATA}/english.txt\", \"English\")\n",
    "afrikaans_data = Corpus(f\"{config.TRAIN_DATA}/afrikaans.txt\", \"Afrikaans\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "0142f911",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5ff35e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:46:10.732898Z",
     "start_time": "2024-07-16T11:46:10.730414Z"
    }
   },
   "source": [
    "# Encoder - source\n",
    "IN_ENCODER = english_data.vocab_size\n",
    "ENCODER_EMB = 256\n",
    "\n",
    "# Decoder - target\n",
    "IN_DECODER = afrikaans_data.vocab_size\n",
    "OUT_DECODER = afrikaans_data.vocab_size\n",
    "DECODER_EMB = 256\n",
    "\n",
    "# Shared\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 8\n",
    "train_data = LangData(english_data, afrikaans_data)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "9b3314f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:46:11.176250Z",
     "start_time": "2024-07-16T11:46:11.173748Z"
    }
   },
   "source": [
    "s, t = next(iter(train_loader))"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "da759f25",
   "metadata": {},
   "source": [
    "## Set the model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:57:04.691066Z",
     "start_time": "2024-07-16T12:57:04.685332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = nn.GRU( input_size = 1, hidden_size = 64, num_layers  = 1 )\n",
    "x = torch.rand(1, 1, 1)\n",
    "output, hn = model(x)"
   ],
   "id": "52abf9d2d34b239c",
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "id": "2e061c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:13:57.511123Z",
     "start_time": "2024-07-16T14:13:57.498013Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, num_layers, bidirectional=False) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.GRU(embd_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: L x B\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded: L x B x E\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, num_layers, bidirectional=False) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        d =  4 if bidirectional else 2\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.GRU(embd_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size * d, input_size)  # Changed concatenation dimension\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        # x: B -> 1 x B\n",
    "        embedded = self.embedding(x.unsqueeze(0))  # Embedded: 1 x B x E\n",
    "        decoded, hidden = self.gru(embedded, hidden)  # Output: 1 x B x H\n",
    "        ##############################################################################################\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        decoded = decoded.permute(1,0,2)\n",
    "        attn_scores = torch.einsum('blh,bih->bl', encoder_outputs, decoded) / np.sqrt(self.gru.hidden_size)  # Use math.sqrt for better compatibility\n",
    "        alpha = attn_scores.softmax(dim=1)  # Alpha: B x L (L - encoder output sequence length)\n",
    "        context = torch.bmm(alpha.unsqueeze(1), encoder_outputs) # Context: 1 x B x H\n",
    "        output = torch.cat((decoded.permute(1,0,2), context.permute(1,0,2)), dim=-1)  # Concatenate on hidden size dimension\n",
    "        ##############################################################################################\n",
    "        prediction = self.fc(output)  # Prediction: 1 x B x V -> B x V_out\n",
    "        return prediction.squeeze(0), hidden\n",
    "\n",
    "    \n",
    "class NeuralMachineTranslation(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_vocab_size):\n",
    "        super(NeuralMachineTranslation, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_size = target_vocab_size\n",
    "\n",
    "    def forward(self, source, target, tch_force=0.9):\n",
    "        target_len, batch_size = target.shape\n",
    "        encoder_output, hidden = self.encoder(source)\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, self.target_size).to(\n",
    "            source.device\n",
    "        )\n",
    "        x = target[0]\n",
    "        hidden = torch.zeros_like(hidden)\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(x, hidden, encoder_output)\n",
    "            outputs[:, t, :] = output\n",
    "            yhat = output.softmax(1).argmax(1)\n",
    "            x = target[t] if np.random.random() < tch_force else yhat\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "def greedy_search(model, source, max_len=20):\n",
    "    end_token = 2\n",
    "    inputs = source[0]\n",
    "    sequence = [1]\n",
    "\n",
    "    encoder_out, hidden = model.encoder(source)\n",
    "    hidden = torch.zeros_like(hidden)\n",
    "    for _ in range(max_len):\n",
    "        output, hidden = model.decoder(inputs, hidden, encoder_out)\n",
    "        top1 = output.argmax(1)\n",
    "        next_token = top1.item()\n",
    "        sequence.append(next_token)\n",
    "\n",
    "        if next_token == end_token:\n",
    "            break\n",
    "\n",
    "        inputs = top1\n",
    "\n",
    "    return sequence\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, model, source_lang, target_lang, device):\n",
    "        self.model = model\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.device = device\n",
    "\n",
    "    def translate_sentence(self, sentence, method=\"greedy\", max_len=20):\n",
    "        text = [\n",
    "            (\n",
    "                self.source_lang.stoi[word]\n",
    "                if word in self.source_lang.stoi\n",
    "                else self.source_lang.stoi[\"<unk>\"]\n",
    "            )\n",
    "            for word in sentence.strip().split()\n",
    "        ]\n",
    "        text = torch.tensor(text, dtype=torch.long).unsqueeze(1).to(self.device)\n",
    "\n",
    "        if method == \"greedy\":\n",
    "            translated = greedy_search(self.model, text, max_len)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: choose between 'greedy' or 'beam'\")\n",
    "\n",
    "        return \" \".join([self.target_lang.itos[idx] for idx in translated])\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 299
  },
  {
   "cell_type": "code",
   "id": "f04f2d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:13:58.471054Z",
     "start_time": "2024-07-16T14:13:58.246317Z"
    }
   },
   "source": [
    "encoder_net = Encoder(IN_ENCODER, ENCODER_EMB, HIDDEN_SIZE, NUM_LAYERS, bidirectional=True).to(device)\n",
    "decoder_net = Decoder(IN_DECODER, DECODER_EMB, HIDDEN_SIZE, NUM_LAYERS, bidirectional=True).to(device)\n",
    "model = NeuralMachineTranslation(encoder_net, decoder_net, OUT_DECODER)"
   ],
   "outputs": [],
   "execution_count": 300
  },
  {
   "cell_type": "code",
   "id": "ee757771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:13:58.525986Z",
     "start_time": "2024-07-16T14:13:58.523433Z"
    }
   },
   "source": [
    "train_data = LangData(english_data, afrikaans_data)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)\n",
    "\n",
    "pad_idx = afrikaans_data.stoi['<pad>']\n",
    "criterion = CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "optimizer = NAdam(model.parameters(), LR)\n",
    "translator = Translator(model, english_data, afrikaans_data, device)"
   ],
   "outputs": [],
   "execution_count": 301
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:13:58.837059Z",
     "start_time": "2024-07-16T14:13:58.764412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data used for follow-up durring training\n",
    "mytext = \"<sos> the classifier makes <num> die klassifiseerder maak <num> korrekte\"\n",
    "ground = \"<sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\"\n",
    "\n",
    "predicted = translator.translate_sentence(mytext)\n",
    "bleu = torch_bleu_score([predicted], [ground])\n",
    "print(f\"Pred: {predicted}\")\n",
    "print(f\"Refe: {ground}\")\n",
    "print(f\"BLEU: {bleu.item()}\")"
   ],
   "id": "bcb89b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <sos> minimeer ewe algemeen algemeen korrek resultaat u voorspellingsfunksie resultaat opmonstering <opn> opmonstering teken intreesein teken minimeer gradi verseker softmax stap\n",
      "Refe: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU: 0.0\n"
     ]
    }
   ],
   "execution_count": 302
  },
  {
   "cell_type": "markdown",
   "id": "2ed66bc3",
   "metadata": {},
   "source": [
    "## Train the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b2790009f0b8f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:27:24.700573Z",
     "start_time": "2024-07-16T14:22:34.454031Z"
    }
   },
   "source": [
    "EPOCHS = 10\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": criterion,\n",
    "    \"device\": device,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"source_test\": mytext,\n",
    "    \"target_test\": ground,\n",
    "    \"translator\": translator\n",
    "}\n",
    "\n",
    "train_model(**params)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 57/57 [00:28<00:00,  1.99batch/s, loss=6.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder totdat totdat totdat totdat konvergeer ere tyd invariante filter wat beskryf word deur die volgende impulsweergawe <opn> fir\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 57/57 [00:28<00:00,  1.97batch/s, loss=4.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> korrekte korrekte <opn> e <cld> re kwantiseringsvlakke nuttig <num> ko effisi ente <num> items <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.268016517162323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 57/57 [00:29<00:00,  1.94batch/s, loss=4.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> korrekte positiewe covid <num> gevalle <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.38571637868881226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 57/57 [00:29<00:00,  1.96batch/s, loss=3.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> totdat dit positiewe covid <num> het of nie <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.25919216871261597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 57/57 [00:29<00:00,  1.95batch/s, loss=3.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.4223605990409851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 57/57 [00:28<00:00,  2.00batch/s, loss=3.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> positiewe positiewe voorspellings en <num> vir die hele <num> ko effisi ente <ltx> <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.3338080048561096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 57/57 [00:28<00:00,  1.99batch/s, loss=3.085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder korrekte <num> korrekte voorspellings <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 57/57 [00:29<00:00,  1.96batch/s, loss=2.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> items in die tyd gebied ooreenstem wat voorheen iterasie <num> voorgekom het <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.218697652220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 57/57 [00:28<00:00,  2.01batch/s, loss=2.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en matriek gemiddeld hoog verdien deur gebruik te maak van <num> hê as\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.3910803198814392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 57/57 [00:29<00:00,  1.90batch/s, loss=2.703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> vir die berekeningspoed <eos>\n",
      "Reference: <sos> die klassifiseerder maak <num> korrekte positiewe voorspellings en <num> <com> <num> korrekte negatiewe voorspellings <eos>\n",
      "BLEU Score: 0.6008310914039612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 304
  },
  {
   "cell_type": "markdown",
   "id": "de635f30",
   "metadata": {},
   "source": [
    "## EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d82ad19d8fc56be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:38:54.096866Z",
     "start_time": "2024-07-16T14:38:31.599964Z"
    }
   },
   "source": [
    "EN_STR = [[' '.join(sent)] for sent in english_data.data_str]\n",
    "AF_STR = [[' '.join(sent)] for sent in afrikaans_data.data_str]\n",
    "TRANSLATED = [[translator.translate_sentence(sent[0])] for sent in EN_STR]"
   ],
   "outputs": [],
   "execution_count": 305
  },
  {
   "cell_type": "code",
   "id": "8d4385cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:38:54.187032Z",
     "start_time": "2024-07-16T14:38:54.098083Z"
    }
   },
   "source": [
    "BLEU_SCORE = [torch_bleu_score(a, b) for a, b in zip(TRANSLATED, AF_STR)]\n",
    "print(f\"Mean BLEU TRAIN {np.mean(BLEU_SCORE)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU TRAIN 0.7932940721511841\n"
     ]
    }
   ],
   "execution_count": 306
  },
  {
   "cell_type": "code",
   "id": "0e88e600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:38:54.191111Z",
     "start_time": "2024-07-16T14:38:54.187767Z"
    }
   },
   "source": [
    "with open(f\"{config.VAL_DATA}/english.txt\") as data:\n",
    "    english_test = data.read().strip().split(\"\\n\")\n",
    "with open(f\"{config.VAL_DATA}/afrikaans.txt\") as data:\n",
    "    afrikaans_test = data.read().strip().split(\"\\n\")\n",
    "AF_TEST = [[sent] for sent in afrikaans_test]"
   ],
   "outputs": [],
   "execution_count": 307
  },
  {
   "cell_type": "code",
   "id": "f61a7571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.680196Z",
     "start_time": "2024-07-16T14:38:54.192453Z"
    }
   },
   "source": "TRANSLATED_VAL = [[translator.translate_sentence(sent)] for sent in english_test]",
   "outputs": [],
   "execution_count": 308
  },
  {
   "cell_type": "code",
   "id": "ff7791dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.702864Z",
     "start_time": "2024-07-16T14:39:02.680905Z"
    }
   },
   "source": [
    "BLEU_VAL = [torch_bleu_score(a, b) for a, b in zip(TRANSLATED_VAL, AF_TEST)]\n",
    "print(f\"Mean BLEU VAL {np.mean(BLEU_VAL)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU VAL 0.029892534017562866\n"
     ]
    }
   ],
   "execution_count": 309
  },
  {
   "cell_type": "code",
   "id": "bae5bb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.705275Z",
     "start_time": "2024-07-16T14:39:02.703555Z"
    }
   },
   "source": [
    "data_eng = [sent.strip().split() for sent in english_test]"
   ],
   "outputs": [],
   "execution_count": 310
  },
  {
   "cell_type": "code",
   "id": "28a707b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.708068Z",
     "start_time": "2024-07-16T14:39:02.705865Z"
    }
   },
   "source": [
    "data_eng1 = []\n",
    "for sent in data_eng:\n",
    "    for word in sent:\n",
    "        data_eng1.append(word if word in english_data.stoi else '<unk>')"
   ],
   "outputs": [],
   "execution_count": 311
  },
  {
   "cell_type": "code",
   "id": "7095ab9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.710254Z",
     "start_time": "2024-07-16T14:39:02.708681Z"
    }
   },
   "source": [
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 312
  },
  {
   "cell_type": "code",
   "id": "31ab58a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.712252Z",
     "start_time": "2024-07-16T14:39:02.710878Z"
    }
   },
   "source": [
    "A = Counter(data_eng1)"
   ],
   "outputs": [],
   "execution_count": 313
  },
  {
   "cell_type": "code",
   "id": "50ea8c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.718338Z",
     "start_time": "2024-07-16T14:39:02.713791Z"
    }
   },
   "source": [
    "A"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'<unk>': 758,\n",
       "         'the': 236,\n",
       "         '<eos>': 194,\n",
       "         '<sos>': 182,\n",
       "         '<num>': 100,\n",
       "         'a': 86,\n",
       "         'of': 82,\n",
       "         'is': 58,\n",
       "         'and': 55,\n",
       "         'to': 54,\n",
       "         '<com>': 43,\n",
       "         'what': 41,\n",
       "         'for': 33,\n",
       "         'system': 25,\n",
       "         'describe': 25,\n",
       "         '<opn>': 24,\n",
       "         '<cld>': 24,\n",
       "         'in': 23,\n",
       "         'an': 22,\n",
       "         'below': 19,\n",
       "         'this': 17,\n",
       "         'on': 16,\n",
       "         'between': 15,\n",
       "         'be': 15,\n",
       "         'that': 15,\n",
       "         'are': 15,\n",
       "         'each': 14,\n",
       "         'c': 14,\n",
       "         'code': 14,\n",
       "         'with': 14,\n",
       "         '<ltx>': 13,\n",
       "         'used': 13,\n",
       "         'your': 12,\n",
       "         'diagram': 12,\n",
       "         'design': 11,\n",
       "         'which': 10,\n",
       "         'from': 10,\n",
       "         'as': 9,\n",
       "         'will': 9,\n",
       "         'time': 9,\n",
       "         'block': 9,\n",
       "         'within': 9,\n",
       "         'you': 9,\n",
       "         'two': 9,\n",
       "         'using': 8,\n",
       "         'write': 8,\n",
       "         'processor': 8,\n",
       "         'can': 8,\n",
       "         'process': 7,\n",
       "         'at': 7,\n",
       "         'answer': 7,\n",
       "         'must': 7,\n",
       "         'draw': 7,\n",
       "         'have': 7,\n",
       "         'difference': 7,\n",
       "         'it': 7,\n",
       "         'given': 7,\n",
       "         'required': 7,\n",
       "         'assume': 6,\n",
       "         'by': 6,\n",
       "         'main': 6,\n",
       "         'execution': 6,\n",
       "         'three': 6,\n",
       "         'table': 6,\n",
       "         'give': 6,\n",
       "         'one': 6,\n",
       "         'i': 6,\n",
       "         'has': 6,\n",
       "         'function': 6,\n",
       "         'ms': 6,\n",
       "         'would': 5,\n",
       "         'if': 5,\n",
       "         'use': 5,\n",
       "         'data': 5,\n",
       "         'all': 5,\n",
       "         'seen': 5,\n",
       "         'after': 4,\n",
       "         'number': 4,\n",
       "         'single': 4,\n",
       "         'following': 4,\n",
       "         'level': 4,\n",
       "         'when': 4,\n",
       "         'does': 4,\n",
       "         'line': 4,\n",
       "         'only': 4,\n",
       "         'show': 4,\n",
       "         'takes': 4,\n",
       "         'every': 4,\n",
       "         'described': 3,\n",
       "         'class': 3,\n",
       "         'speed': 3,\n",
       "         'classes': 3,\n",
       "         'least': 3,\n",
       "         'other': 3,\n",
       "         'image': 3,\n",
       "         'shortly': 3,\n",
       "         'output': 3,\n",
       "         'part': 3,\n",
       "         'executed': 3,\n",
       "         'explain': 3,\n",
       "         'how': 3,\n",
       "         'indicate': 3,\n",
       "         'shown': 3,\n",
       "         'implemented': 3,\n",
       "         'method': 3,\n",
       "         'was': 3,\n",
       "         'lines': 3,\n",
       "         'above': 3,\n",
       "         'or': 3,\n",
       "         'power': 3,\n",
       "         'up': 2,\n",
       "         'requirements': 2,\n",
       "         'its': 2,\n",
       "         'ground': 2,\n",
       "         'functions': 2,\n",
       "         'refer': 2,\n",
       "         'before': 2,\n",
       "         'frame': 2,\n",
       "         'defined': 2,\n",
       "         'first': 2,\n",
       "         'determine': 2,\n",
       "         'different': 2,\n",
       "         'more': 2,\n",
       "         'case': 2,\n",
       "         'equivalent': 2,\n",
       "         'terms': 2,\n",
       "         'list': 2,\n",
       "         'means': 2,\n",
       "         'based': 2,\n",
       "         'optimise': 2,\n",
       "         'multiple': 2,\n",
       "         'base': 2,\n",
       "         'sum': 2,\n",
       "         'same': 2,\n",
       "         'complete': 2,\n",
       "         'full': 2,\n",
       "         'average': 2,\n",
       "         'sample': 2,\n",
       "         'audio': 2,\n",
       "         'set': 2,\n",
       "         'calculate': 2,\n",
       "         'assuming': 2,\n",
       "         'their': 2,\n",
       "         'components': 2,\n",
       "         'wants': 2,\n",
       "         'but': 2,\n",
       "         'not': 2,\n",
       "         'why': 2,\n",
       "         'changes': 2,\n",
       "         'makes': 2,\n",
       "         'than': 2,\n",
       "         'nodes': 2,\n",
       "         'work': 2,\n",
       "         'do': 2,\n",
       "         'through': 2,\n",
       "         'times': 2,\n",
       "         'energy': 2,\n",
       "         'any': 2,\n",
       "         'over': 2,\n",
       "         'transfer': 2,\n",
       "         'shows': 2,\n",
       "         'so': 2,\n",
       "         's': 2,\n",
       "         'texttt': 2,\n",
       "         'high': 2,\n",
       "         '<apo>': 2,\n",
       "         'cross': 2,\n",
       "         'analysis': 1,\n",
       "         'systems': 1,\n",
       "         'followed': 1,\n",
       "         'levels': 1,\n",
       "         'order': 1,\n",
       "         'we': 1,\n",
       "         'choose': 1,\n",
       "         'motivate': 1,\n",
       "         'final': 1,\n",
       "         'launched': 1,\n",
       "         'necessary': 1,\n",
       "         'aim': 1,\n",
       "         'include': 1,\n",
       "         'next': 1,\n",
       "         'new': 1,\n",
       "         'been': 1,\n",
       "         'saving': 1,\n",
       "         'models': 1,\n",
       "         'white': 1,\n",
       "         'testing': 1,\n",
       "         'step': 1,\n",
       "         'assignment': 1,\n",
       "         'form': 1,\n",
       "         'graph': 1,\n",
       "         'see': 1,\n",
       "         'methods': 1,\n",
       "         'rate': 1,\n",
       "         'needs': 1,\n",
       "         'periodic': 1,\n",
       "         'provided': 1,\n",
       "         'perform': 1,\n",
       "         'efficient': 1,\n",
       "         'computations': 1,\n",
       "         't': 1,\n",
       "         'algorithm': 1,\n",
       "         'currently': 1,\n",
       "         'calculates': 1,\n",
       "         'result': 1,\n",
       "         'decide': 1,\n",
       "         'into': 1,\n",
       "         'state': 1,\n",
       "         'machine': 1,\n",
       "         'textbf': 1,\n",
       "         'example': 1,\n",
       "         'add': 1,\n",
       "         'smallest': 1,\n",
       "         'until': 1,\n",
       "         'values': 1,\n",
       "         'vector': 1,\n",
       "         'direct': 1,\n",
       "         'configuration': 1,\n",
       "         'technique': 1,\n",
       "         'improve': 1,\n",
       "         'most': 1,\n",
       "         'adc': 1,\n",
       "         'zeros': 1,\n",
       "         'signal': 1,\n",
       "         'bits': 1,\n",
       "         'per': 1,\n",
       "         'sampled': 1,\n",
       "         'khz': 1,\n",
       "         'non': 1,\n",
       "         'also': 1,\n",
       "         'minimum': 1,\n",
       "         'some': 1,\n",
       "         'them': 1,\n",
       "         'clearly': 1,\n",
       "         'signals': 1,\n",
       "         'should': 1,\n",
       "         'b': 1,\n",
       "         'possible': 1,\n",
       "         'change': 1,\n",
       "         'ideal': 1,\n",
       "         'scenario': 1,\n",
       "         'sketch': 1,\n",
       "         'run': 1,\n",
       "         'model': 1,\n",
       "         'these': 1,\n",
       "         'settings': 1,\n",
       "         'uses': 1,\n",
       "         'fixed': 1,\n",
       "         'processing': 1,\n",
       "         'want': 1,\n",
       "         'follows': 1,\n",
       "         'works': 1,\n",
       "         'implement': 1,\n",
       "         'look': 1,\n",
       "         'term': 1,\n",
       "         'textit': 1,\n",
       "         'they': 1,\n",
       "         'way': 1,\n",
       "         'associative': 1,\n",
       "         'back': 1,\n",
       "         'written': 1,\n",
       "         'ratio': 1,\n",
       "         'factors': 1,\n",
       "         'compared': 1,\n",
       "         'unit': 1,\n",
       "         'around': 1,\n",
       "         'calculations': 1,\n",
       "         'maximum': 1,\n",
       "         'make': 1,\n",
       "         'decided': 1,\n",
       "         'contains': 1,\n",
       "         'ways': 1,\n",
       "         'measure': 1,\n",
       "         'like': 1,\n",
       "         'test': 1,\n",
       "         'observation': 1,\n",
       "         'additional': 1,\n",
       "         'effect': 1})"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 314
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412c869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
