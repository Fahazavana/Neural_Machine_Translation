{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88716432",
   "metadata": {},
   "source": [
    "# NEURAL MACHINE TRANSLATION - GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4bb18",
   "metadata": {},
   "source": [
    "## Required Module & Config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89bf9e4-311d-4af8-846b-ccfcb9e940b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:06:05.703509Z",
     "start_time": "2024-07-16T19:06:04.086993Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import NAdam\n",
    "\n",
    "from src.Tokenizer import Corpus, LangData, dataLoader\n",
    "from src.utils import load_config, get_device, train_model\n",
    "\n",
    "from src.Normalizer import preprocess_data\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e500dcfdf8cad39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:06:05.717503Z",
     "start_time": "2024-07-16T19:06:05.704895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Loading config file\n",
    "config = load_config()\n",
    "# Get device : GPU/MPS Back-End/CPU\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4461b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa220702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:06:05.720175Z",
     "start_time": "2024-07-16T19:06:05.718420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for english!\n",
      "Done for afrikaans!\n",
      "Done for english!\n",
      "Done for afrikaans!\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_DATA\n",
    "preprocess_data(config.TRAIN_RAW, config.TRAIN_DATA, config.TRAIN_SOURCE, \"english\")\n",
    "preprocess_data(config.TRAIN_RAW, config.TRAIN_DATA, config.TRAIN_TARGET, \"afrikaans\")\n",
    "\n",
    "# VAL_DATA\n",
    "preprocess_data(config.VAL_RAW, config.VAL_DATA, config.VAL_SOURCE, \"english\")\n",
    "preprocess_data(config.VAL_RAW, config.VAL_DATA, config.VAL_TARGET, \"afrikaans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76325a3f",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083f4d8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:06:05.946750Z",
     "start_time": "2024-07-16T19:06:05.924440Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder-Source\n",
    "english_data = Corpus(f\"{config.TRAIN_DATA}/english.txt\", \"English\")\n",
    "afrikaans_data = Corpus(f\"{config.TRAIN_DATA}/afrikaans.txt\", \"Afrikaans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0142f911",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ff35e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:10:33.861198Z",
     "start_time": "2024-07-16T19:10:33.857667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder - source\n",
    "IN_ENCODER = english_data.vocab_size\n",
    "ENCODER_EMB = 256\n",
    "\n",
    "# Decoder - target\n",
    "IN_DECODER = afrikaans_data.vocab_size\n",
    "OUT_DECODER = afrikaans_data.vocab_size\n",
    "DECODER_EMB = 256\n",
    "\n",
    "# Shared\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "train_data = LangData(english_data, afrikaans_data)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da759f25",
   "metadata": {},
   "source": [
    "## Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e061c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:10:35.515761Z",
     "start_time": "2024-07-16T19:10:35.499049Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, num_layers, bidirectional=False) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.GRU(embd_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: L x B\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded: L x B x E\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embd_size, hidden_size, num_layers, bidirectional=False) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        d =  4 if bidirectional else 2\n",
    "        self.embedding = nn.Embedding(input_size, embd_size)\n",
    "        self.gru = nn.GRU(embd_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size * d, input_size)  # Changed concatenation dimension\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        # x: B -> 1 x B\n",
    "        embedded = self.embedding(x.unsqueeze(0))  # Embedded: 1 x B x E\n",
    "        decoded, hidden = self.gru(embedded, hidden)  # Output: 1 x B x H\n",
    "        ##############################################################################################\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        decoded = decoded.permute(1,0,2)\n",
    "        attn_scores = torch.einsum('blh,bih->bl', encoder_outputs, decoded) / np.sqrt(self.gru.hidden_size) \n",
    "        alpha = attn_scores.softmax(dim=1)  # Alpha: B x L (L - encoder output sequence length)\n",
    "        context = torch.bmm(alpha.unsqueeze(1), encoder_outputs) # Context: 1 x B x H\n",
    "        output = torch.cat((decoded.permute(1,0,2), context.permute(1,0,2)), dim=-1)  # Concatenate on hidden size dimension\n",
    "        ##############################################################################################\n",
    "        prediction = self.fc(output)  # Prediction: 1 x B x V -> B x V_out\n",
    "        return prediction.squeeze(0), hidden\n",
    "\n",
    "    \n",
    "class NeuralMachineTranslation(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_vocab_size):\n",
    "        super(NeuralMachineTranslation, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_size = target_vocab_size\n",
    "\n",
    "    def forward(self, source, target, tch_force=0.9):\n",
    "        target_len, batch_size = target.shape\n",
    "        encoder_output, hidden = self.encoder(source)\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, self.target_size).to(\n",
    "            source.device\n",
    "        )\n",
    "        x = target[0]\n",
    "        hidden = torch.zeros_like(hidden)\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(x, hidden, encoder_output)\n",
    "            outputs[:, t, :] = output\n",
    "            yhat = output.softmax(1).argmax(1)\n",
    "            x = target[t] if np.random.random() < tch_force else yhat\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "def greedy_search(model, source, max_len=20):\n",
    "    end_token = 2\n",
    "    inputs = source[0]\n",
    "    sequence = [1]\n",
    "\n",
    "    encoder_out, hidden = model.encoder(source)\n",
    "    hidden = torch.zeros_like(hidden)\n",
    "    for _ in range(max_len):\n",
    "        output, hidden = model.decoder(inputs, hidden, encoder_out)\n",
    "        top1 = output.argmax(1)\n",
    "        next_token = top1.item()\n",
    "        sequence.append(next_token)\n",
    "\n",
    "        if next_token == end_token:\n",
    "            break\n",
    "\n",
    "        inputs = top1\n",
    "\n",
    "    return sequence\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, model, source_lang, target_lang, device):\n",
    "        self.model = model\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.device = device\n",
    "\n",
    "    def translate_sentence(self, sentence, method=\"greedy\", max_len=20):\n",
    "        text = [\n",
    "            (\n",
    "                self.source_lang.stoi[word]\n",
    "                if word in self.source_lang.stoi\n",
    "                else self.source_lang.stoi[\"<unk>\"]\n",
    "            )\n",
    "            for word in sentence.strip().split()\n",
    "        ]\n",
    "        text = torch.tensor(text, dtype=torch.long).unsqueeze(1).to(self.device)\n",
    "\n",
    "        if method == \"greedy\":\n",
    "            translated = greedy_search(self.model, text, max_len)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: choose between 'greedy' or 'beam'\")\n",
    "\n",
    "        return \" \".join([self.target_lang.itos[idx] for idx in translated])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04f2d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:10:36.821935Z",
     "start_time": "2024-07-16T19:10:36.443616Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_net = Encoder(IN_ENCODER, ENCODER_EMB, HIDDEN_SIZE, NUM_LAYERS, bidirectional=True).to(device)\n",
    "decoder_net = Decoder(IN_DECODER, DECODER_EMB, HIDDEN_SIZE, NUM_LAYERS, bidirectional=True).to(device)\n",
    "model = NeuralMachineTranslation(encoder_net, decoder_net, OUT_DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee757771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:10:37.188014Z",
     "start_time": "2024-07-16T19:10:37.184864Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = LangData(english_data, afrikaans_data)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)\n",
    "\n",
    "pad_idx = afrikaans_data.stoi['<pad>']\n",
    "criterion = CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "optimizer = NAdam(model.parameters(), LR)\n",
    "translator = Translator(model, english_data, afrikaans_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcbef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a778cef9b1400b9c06d6ddffb0f05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e32bf9e8704722ad72b1e562113000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dd275bffb04259925004d14f6251fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb89b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:10:38.250678Z",
     "start_time": "2024-07-16T19:10:38.105814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <sos> \"so vind vind sukses kode gesondheid (idft) belê.\" gee gee studie studie pong pong glas afstaan omstander omstander soet soet\n",
      "Refe: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "bleu                : 0.0\n",
      "precisions          : [0.10714285714285714, 0.07407407407407407, 0.038461538461538464, 0.0]\n",
      "brevity_penalty     : 0.6751251871527363\n",
      "length_ratio        : 0.717948717948718\n",
      "translation_length  : 28\n",
      "reference_length    : 39\n"
     ]
    }
   ],
   "source": [
    "# Data used for follow-up durring training\n",
    "mytext = \"<sos> given that we represent the target output as $y\\in\\{0,1\\}$ and we have $n$ training points , we can write the negative log likelihood of the parameters as follows: <eos>\"\n",
    "ground = \"<sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\"\n",
    "predicted = translator.translate_sentence(mytext)\n",
    "bleu = metric.compute(predictions=[predicted], references=[ground])\n",
    "print(f\"Pred: {predicted}\")\n",
    "print(f\"Refe: {ground}\")\n",
    "for key, val in bleu.items():\n",
    "\tprint(f\"{key:<20}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed66bc3",
   "metadata": {},
   "source": [
    "## Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b2790009f0b8f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:16:25.338328Z",
     "start_time": "2024-07-16T19:10:40.907324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 20/20 [00:24<00:00,  1.23s/batch, loss=1.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> die filter filter die kat filter die filter filter die oordragsfunksie filter die filter filter die oordragsfunksie filter die filter\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 20/20 [00:23<00:00,  1.18s/batch, loss=1.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> ons het die data , met die frekwensie frekwensie , en die frekwensie in die tyd-gebied <eos>\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 20/20 [00:23<00:00,  1.19s/batch, loss=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> ons het die hele van die stelsel wat deur die volgende vergelyking beskryf word : <eos>\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 20/20 [00:23<00:00,  1.20s/batch, loss=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> as ons die teikenuittree voorstel voorstel en ons het ons die $2n$ log-waarskynlikheidskostefunksie voorstel voorstel en ons salaris die $2n$\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.2631388306617737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 20/20 [00:24<00:00,  1.21s/batch, loss=0.424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> as ons die teikenuittree voorstel voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte , dan kan ons die negatiewe voorstel as\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.6496115922927856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 20/20 [00:59<00:00,  2.95s/batch, loss=0.354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> as ons die teikenuittree voorstel voorstel en ons het $n$ monsters , en ons kan die negatiewe log-waarskynlikheidskostefunksie skryf as\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.3687663674354553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 20/20 [00:24<00:00,  1.20s/batch, loss=0.307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte afrigpunte , kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.7020458579063416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 20/20 [00:24<00:00,  1.21s/batch, loss=0.280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf\n",
      "Reference: <sos> as ons die teikenuittree voorstel as $y\\in\\{0,1\\}$ en ons $n$ afrigpunte het , dan kan ons die negatiewe log-waarskynlikheidskostefunksie skryf as: <eos>\n",
      "BLEU Score: 0.9091564416885376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  10%|█         | 2/20 [00:01<00:16,  1.11batch/s, loss=0.020]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": criterion,\n",
    "    \"device\": device,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"source_test\": mytext,\n",
    "    \"target_test\": ground,\n",
    "    \"translator\": translator\n",
    "}\n",
    "\n",
    "train_model(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de635f30",
   "metadata": {},
   "source": [
    "## EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d82ad19d8fc56be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:19:07.820566Z",
     "start_time": "2024-07-16T19:16:51.693873Z"
    }
   },
   "outputs": [],
   "source": [
    "EN_STR = [[' '.join(sent)] for sent in english_data.data_str]\n",
    "AF_STR = [[' '.join(sent)] for sent in afrikaans_data.data_str]\n",
    "TRANSLATED = [[translator.translate_sentence(sent[0])] for sent in EN_STR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d4385cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:19:08.511789Z",
     "start_time": "2024-07-16T19:19:07.821883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU TRAIN 0.9447808861732483\n"
     ]
    }
   ],
   "source": [
    "BLEU_SCORE = [torch_bleu_score(a, b) for a, b in zip(TRANSLATED, AF_STR)]\n",
    "print(f\"Mean BLEU TRAIN {np.mean(BLEU_SCORE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e88e600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:19:51.550698Z",
     "start_time": "2024-07-16T19:19:51.546555Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{config.VAL_DATA}/english.txt\") as data:\n",
    "    english_test = data.read().strip().split(\"\\n\")\n",
    "with open(f\"{config.VAL_DATA}/afrikaans.txt\") as data:\n",
    "    afrikaans_test = data.read().strip().split(\"\\n\")\n",
    "AF_TEST = [[sent] for sent in afrikaans_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f61a7571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:20:03.184332Z",
     "start_time": "2024-07-16T19:19:52.172350Z"
    }
   },
   "outputs": [],
   "source": [
    "TRANSLATED_VAL = [[translator.translate_sentence(sent)] for sent in english_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff7791dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T19:20:03.215970Z",
     "start_time": "2024-07-16T19:20:03.185656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU VAL 0.03426128998398781\n"
     ]
    }
   ],
   "source": [
    "BLEU_VAL = [torch_bleu_score(a, b) for a, b in zip(TRANSLATED_VAL, AF_TEST)]\n",
    "print(f\"Mean BLEU VAL {np.mean(BLEU_VAL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "bae5bb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.705275Z",
     "start_time": "2024-07-16T14:39:02.703555Z"
    }
   },
   "outputs": [],
   "source": [
    "data_eng = [sent.strip().split() for sent in english_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "28a707b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.708068Z",
     "start_time": "2024-07-16T14:39:02.705865Z"
    }
   },
   "outputs": [],
   "source": [
    "data_eng1 = []\n",
    "for sent in data_eng:\n",
    "    for word in sent:\n",
    "        data_eng1.append(word if word in english_data.stoi else '<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7095ab9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.710254Z",
     "start_time": "2024-07-16T14:39:02.708681Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "31ab58a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.712252Z",
     "start_time": "2024-07-16T14:39:02.710878Z"
    }
   },
   "outputs": [],
   "source": [
    "A = Counter(data_eng1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "50ea8c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T14:39:02.718338Z",
     "start_time": "2024-07-16T14:39:02.713791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'<unk>': 758,\n",
       "         'the': 236,\n",
       "         '<eos>': 194,\n",
       "         '<sos>': 182,\n",
       "         '<num>': 100,\n",
       "         'a': 86,\n",
       "         'of': 82,\n",
       "         'is': 58,\n",
       "         'and': 55,\n",
       "         'to': 54,\n",
       "         '<com>': 43,\n",
       "         'what': 41,\n",
       "         'for': 33,\n",
       "         'system': 25,\n",
       "         'describe': 25,\n",
       "         '<opn>': 24,\n",
       "         '<cld>': 24,\n",
       "         'in': 23,\n",
       "         'an': 22,\n",
       "         'below': 19,\n",
       "         'this': 17,\n",
       "         'on': 16,\n",
       "         'between': 15,\n",
       "         'be': 15,\n",
       "         'that': 15,\n",
       "         'are': 15,\n",
       "         'each': 14,\n",
       "         'c': 14,\n",
       "         'code': 14,\n",
       "         'with': 14,\n",
       "         '<ltx>': 13,\n",
       "         'used': 13,\n",
       "         'your': 12,\n",
       "         'diagram': 12,\n",
       "         'design': 11,\n",
       "         'which': 10,\n",
       "         'from': 10,\n",
       "         'as': 9,\n",
       "         'will': 9,\n",
       "         'time': 9,\n",
       "         'block': 9,\n",
       "         'within': 9,\n",
       "         'you': 9,\n",
       "         'two': 9,\n",
       "         'using': 8,\n",
       "         'write': 8,\n",
       "         'processor': 8,\n",
       "         'can': 8,\n",
       "         'process': 7,\n",
       "         'at': 7,\n",
       "         'answer': 7,\n",
       "         'must': 7,\n",
       "         'draw': 7,\n",
       "         'have': 7,\n",
       "         'difference': 7,\n",
       "         'it': 7,\n",
       "         'given': 7,\n",
       "         'required': 7,\n",
       "         'assume': 6,\n",
       "         'by': 6,\n",
       "         'main': 6,\n",
       "         'execution': 6,\n",
       "         'three': 6,\n",
       "         'table': 6,\n",
       "         'give': 6,\n",
       "         'one': 6,\n",
       "         'i': 6,\n",
       "         'has': 6,\n",
       "         'function': 6,\n",
       "         'ms': 6,\n",
       "         'would': 5,\n",
       "         'if': 5,\n",
       "         'use': 5,\n",
       "         'data': 5,\n",
       "         'all': 5,\n",
       "         'seen': 5,\n",
       "         'after': 4,\n",
       "         'number': 4,\n",
       "         'single': 4,\n",
       "         'following': 4,\n",
       "         'level': 4,\n",
       "         'when': 4,\n",
       "         'does': 4,\n",
       "         'line': 4,\n",
       "         'only': 4,\n",
       "         'show': 4,\n",
       "         'takes': 4,\n",
       "         'every': 4,\n",
       "         'described': 3,\n",
       "         'class': 3,\n",
       "         'speed': 3,\n",
       "         'classes': 3,\n",
       "         'least': 3,\n",
       "         'other': 3,\n",
       "         'image': 3,\n",
       "         'shortly': 3,\n",
       "         'output': 3,\n",
       "         'part': 3,\n",
       "         'executed': 3,\n",
       "         'explain': 3,\n",
       "         'how': 3,\n",
       "         'indicate': 3,\n",
       "         'shown': 3,\n",
       "         'implemented': 3,\n",
       "         'method': 3,\n",
       "         'was': 3,\n",
       "         'lines': 3,\n",
       "         'above': 3,\n",
       "         'or': 3,\n",
       "         'power': 3,\n",
       "         'up': 2,\n",
       "         'requirements': 2,\n",
       "         'its': 2,\n",
       "         'ground': 2,\n",
       "         'functions': 2,\n",
       "         'refer': 2,\n",
       "         'before': 2,\n",
       "         'frame': 2,\n",
       "         'defined': 2,\n",
       "         'first': 2,\n",
       "         'determine': 2,\n",
       "         'different': 2,\n",
       "         'more': 2,\n",
       "         'case': 2,\n",
       "         'equivalent': 2,\n",
       "         'terms': 2,\n",
       "         'list': 2,\n",
       "         'means': 2,\n",
       "         'based': 2,\n",
       "         'optimise': 2,\n",
       "         'multiple': 2,\n",
       "         'base': 2,\n",
       "         'sum': 2,\n",
       "         'same': 2,\n",
       "         'complete': 2,\n",
       "         'full': 2,\n",
       "         'average': 2,\n",
       "         'sample': 2,\n",
       "         'audio': 2,\n",
       "         'set': 2,\n",
       "         'calculate': 2,\n",
       "         'assuming': 2,\n",
       "         'their': 2,\n",
       "         'components': 2,\n",
       "         'wants': 2,\n",
       "         'but': 2,\n",
       "         'not': 2,\n",
       "         'why': 2,\n",
       "         'changes': 2,\n",
       "         'makes': 2,\n",
       "         'than': 2,\n",
       "         'nodes': 2,\n",
       "         'work': 2,\n",
       "         'do': 2,\n",
       "         'through': 2,\n",
       "         'times': 2,\n",
       "         'energy': 2,\n",
       "         'any': 2,\n",
       "         'over': 2,\n",
       "         'transfer': 2,\n",
       "         'shows': 2,\n",
       "         'so': 2,\n",
       "         's': 2,\n",
       "         'texttt': 2,\n",
       "         'high': 2,\n",
       "         '<apo>': 2,\n",
       "         'cross': 2,\n",
       "         'analysis': 1,\n",
       "         'systems': 1,\n",
       "         'followed': 1,\n",
       "         'levels': 1,\n",
       "         'order': 1,\n",
       "         'we': 1,\n",
       "         'choose': 1,\n",
       "         'motivate': 1,\n",
       "         'final': 1,\n",
       "         'launched': 1,\n",
       "         'necessary': 1,\n",
       "         'aim': 1,\n",
       "         'include': 1,\n",
       "         'next': 1,\n",
       "         'new': 1,\n",
       "         'been': 1,\n",
       "         'saving': 1,\n",
       "         'models': 1,\n",
       "         'white': 1,\n",
       "         'testing': 1,\n",
       "         'step': 1,\n",
       "         'assignment': 1,\n",
       "         'form': 1,\n",
       "         'graph': 1,\n",
       "         'see': 1,\n",
       "         'methods': 1,\n",
       "         'rate': 1,\n",
       "         'needs': 1,\n",
       "         'periodic': 1,\n",
       "         'provided': 1,\n",
       "         'perform': 1,\n",
       "         'efficient': 1,\n",
       "         'computations': 1,\n",
       "         't': 1,\n",
       "         'algorithm': 1,\n",
       "         'currently': 1,\n",
       "         'calculates': 1,\n",
       "         'result': 1,\n",
       "         'decide': 1,\n",
       "         'into': 1,\n",
       "         'state': 1,\n",
       "         'machine': 1,\n",
       "         'textbf': 1,\n",
       "         'example': 1,\n",
       "         'add': 1,\n",
       "         'smallest': 1,\n",
       "         'until': 1,\n",
       "         'values': 1,\n",
       "         'vector': 1,\n",
       "         'direct': 1,\n",
       "         'configuration': 1,\n",
       "         'technique': 1,\n",
       "         'improve': 1,\n",
       "         'most': 1,\n",
       "         'adc': 1,\n",
       "         'zeros': 1,\n",
       "         'signal': 1,\n",
       "         'bits': 1,\n",
       "         'per': 1,\n",
       "         'sampled': 1,\n",
       "         'khz': 1,\n",
       "         'non': 1,\n",
       "         'also': 1,\n",
       "         'minimum': 1,\n",
       "         'some': 1,\n",
       "         'them': 1,\n",
       "         'clearly': 1,\n",
       "         'signals': 1,\n",
       "         'should': 1,\n",
       "         'b': 1,\n",
       "         'possible': 1,\n",
       "         'change': 1,\n",
       "         'ideal': 1,\n",
       "         'scenario': 1,\n",
       "         'sketch': 1,\n",
       "         'run': 1,\n",
       "         'model': 1,\n",
       "         'these': 1,\n",
       "         'settings': 1,\n",
       "         'uses': 1,\n",
       "         'fixed': 1,\n",
       "         'processing': 1,\n",
       "         'want': 1,\n",
       "         'follows': 1,\n",
       "         'works': 1,\n",
       "         'implement': 1,\n",
       "         'look': 1,\n",
       "         'term': 1,\n",
       "         'textit': 1,\n",
       "         'they': 1,\n",
       "         'way': 1,\n",
       "         'associative': 1,\n",
       "         'back': 1,\n",
       "         'written': 1,\n",
       "         'ratio': 1,\n",
       "         'factors': 1,\n",
       "         'compared': 1,\n",
       "         'unit': 1,\n",
       "         'around': 1,\n",
       "         'calculations': 1,\n",
       "         'maximum': 1,\n",
       "         'make': 1,\n",
       "         'decided': 1,\n",
       "         'contains': 1,\n",
       "         'ways': 1,\n",
       "         'measure': 1,\n",
       "         'like': 1,\n",
       "         'test': 1,\n",
       "         'observation': 1,\n",
       "         'additional': 1,\n",
       "         'effect': 1})"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412c869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
