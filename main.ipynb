{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89bf9e4-311d-4af8-846b-ccfcb9e940b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Normalizer import preprocess_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e72ac",
   "metadata": {},
   "source": [
    "# DATA PERPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587e9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE = \"./data\"\n",
    "TRAIN_RAW = f\"{DATA_BASE}/train\"\n",
    "TRAIN_DATA = f\"{TRAIN_RAW}/norm\"\n",
    "\n",
    "VAL_RAW = f\"{DATA_BASE}/val\"\n",
    "VAL_DATA = f\"{VAL_RAW}/norm\"\n",
    "\n",
    "TRAIN_AFRIKAANS = [\n",
    "\t\"data414_2021_a1.af.txt\",\n",
    "\t\"data414_2021_a2.af.txt\",\n",
    "\t\"data414_2020_a1.af.txt\",\n",
    "\t\"ss414_2018_a1.af.txt\",\n",
    "\t\"ss414_2018_a2.af.txt\",\n",
    "\t\"ss414_2018_a3.af.txt\",\n",
    "\t\"ss414_2019_a1.af.txt\",\n",
    "\t\"ss414_2019_a2.af.txt\",\n",
    "\t\"ss414_2019_a3.af.txt\",]\n",
    "\n",
    "TRAIN_ENGLISH = [\n",
    "\t\"data414_2021_a1.en.txt\",\n",
    "\t\"data414_2021_a2.en.txt\",\n",
    "\t\"data414_2020_a1.en.txt\",\n",
    "\t\"ss414_2018_a1.en.txt\",\n",
    "\t\"ss414_2018_a2.en.txt\",\n",
    "\t\"ss414_2018_a3.en.txt\",\n",
    "\t\"ss414_2019_a1.en.txt\",\n",
    "\t\"ss414_2019_a2.en.txt\",\n",
    "\t\"ss414_2019_a3.en.txt\",]\n",
    "\n",
    "VAL_AFRIKAANS = [\n",
    "\t\"compsys414_2017_a1.af.txt\",\n",
    "\t\"compsys414_2017_a2.af.txt\",\n",
    "\t\"compsys414_2017_a3.af.txt\",]\n",
    "\n",
    "VAL_ENGLISH = [\n",
    "\t\"compsys414_2017_a1.en.txt\",\n",
    "\t\"compsys414_2017_a2.en.txt\",\n",
    "\t\"compsys414_2017_a3.en.txt\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa220702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN_DATA\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(TRAIN_RAW, TRAIN_DATA, TRAIN_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c937e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VAL_DATA\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_AFRIKAANS, \"afrikaans\")\n",
    "# preprocess_data(VAL_RAW, VAL_DATA, VAL_ENGLISH, \"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3aca5",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46481871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\tdef __init__(self, file_name: str, lang:str):\n",
    "\t\tself.file_name = file_name\n",
    "\t\tself.lang = lang\n",
    "\t\tself.vocab_size = 11\n",
    "\t\tself.data = []\n",
    "\t\tself.stoi: Dict[str, int] = {\n",
    "\t\t\t\"<pad>\": 0,\n",
    "\t\t\t\"<sos>\": 1,\n",
    "\t\t\t\"<eos>\": 2,\n",
    "\t\t\t\"<unk>\": 3,\n",
    "\t\t\t\"<num>\": 4,\n",
    "\t\t\t\"<com>\": 5,\n",
    "\t\t\t\"<prc>\": 6,\n",
    "\t\t\t\"<opn>\": 7,\n",
    "\t\t\t\"<cld>\": 8,\n",
    "\t\t\t\"<apo>\": 9,\n",
    "\t\t\t\"<ltx>\": 10,\n",
    "\t\t}\n",
    "\t\tself.itos: Dict[int, str] = {\n",
    "\t\t\t0: \"<pad>\",\n",
    "\t\t\t1: \"<sos>\",\n",
    "\t\t\t2: \"<eos>\",\n",
    "\t\t\t3: \"<unk>\",\n",
    "\t\t\t4: \"<num>\",\n",
    "\t\t\t5: \"<com>\",\n",
    "\t\t\t6: \"<prc>\",\n",
    "\t\t\t7: \"<opn>\",\n",
    "\t\t\t8: \"<cld>\",\n",
    "\t\t\t9: \"<apo>\",\n",
    "\t\t\t10: \"<ltx>\",\n",
    "\t\t}\n",
    "\t\tself.__init_data()\n",
    "\t\tself.__encode()\n",
    "\n",
    "\tdef __init_data(self):\n",
    "\t\twith open(self.file_name, \"r\") as file:\n",
    "\t\t\tfor line in file:\n",
    "\t\t\t\tline = line.strip().split()\n",
    "\t\t\t\tself.data.append(line)\n",
    "\t\t\t\tfor word in line:\n",
    "\t\t\t\t\tif not self.stoi.get(word):\n",
    "\t\t\t\t\t\tself.vocab_size += 1\n",
    "\t\t\t\t\t\tself.stoi[word] = self.vocab_size - 1\n",
    "\t\t\t\t\t\tself.itos[self.vocab_size-1] = word\n",
    "\tdef __encode(self):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in self.data]\n",
    "\t\tself.data = _data\n",
    "\t\t\n",
    "\tdef decode(self, data):\n",
    "\t\t_data = [[self.stoi[word] for word in sentence] for sentence in data]\n",
    "\t\treturn _data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a26988",
   "metadata": {},
   "source": [
    "## Torch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3aad3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea08ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangData(Dataset):\n",
    "\tdef __init__(self, source, target):\n",
    "\t\tif len(source.data) != len(target.data):\n",
    "\t\t\traise RuntimeError(\"Source and target must have the same lenght\")\n",
    "\t\tself.source = source.data\n",
    "\t\tself.target = target.data\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tx = torch.tensor(self.source[idx], dtype=torch.long)\n",
    "\t\ty = torch.tensor(self.target[idx], dtype=torch.long)\n",
    "\t\treturn x, y\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.source)\n",
    "\n",
    "def collate_fn(batch):\n",
    "\t\"\"\"\n",
    "\t Pad shorter sequence with 0 (<pad>) to match the longest sequence\n",
    "\t to obtain a uniform bacht size.\n",
    "\t\"\"\"\n",
    "\tsource, target = zip(*batch)\n",
    "\t# Pad sequences\n",
    "\tsource = pad_sequence(source, batch_first=False, padding_value=0)\n",
    "\ttarget = pad_sequence(target, batch_first=False, padding_value=0)\n",
    "\treturn source, target\n",
    "\n",
    "\n",
    "def dataLoader(dataset, batch_size):\n",
    "\treturn DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7213a5",
   "metadata": {},
   "source": [
    "## NMT: AFRIKAANS -> ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10db208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if torch.backends.mps.is_available:\n",
    "\tdevice = \"mps\"  # OSX\n",
    "elif torch.cuda.is_available:\n",
    "\tdevice = \"cuda\"\n",
    "else:\n",
    "\tdevice = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5dc571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, input_size, embd_size, hidden_size, num_layers) -> None:\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.num_layers = num_layers\n",
    "\n",
    "\t\tself.embedding = nn.Embedding(input_size, embd_size)\n",
    "\t\tself.rnn = nn.LSTM(input_size=embd_size, hidden_size=hidden_size,\n",
    "\t\t\t\t\t\t   num_layers=num_layers)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x: L x B\n",
    "\t\te = self.embedding(x)\n",
    "\t\t# e: L x B x E\n",
    "\t\t_, (hidden, cell) = self.rnn(e)\n",
    "\t\treturn hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, input_size, embd_size, hidden_size, output_size, num_layers) -> None:\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.num_layers = num_layers\n",
    "\t\tself.embedding = nn.Embedding(input_size, embd_size)\n",
    "\t\tself.rnn = nn.LSTM(embd_size, hidden_size,\n",
    "\t\t\t\t\t\t   num_layers)\n",
    "\t\tself.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\tdef forward(self, x, hidden, cell):\n",
    "\t\t# x: B -> 1 x B\n",
    "\t\te = self.embedding(x.unsqueeze(0))\n",
    "\t\t# e: 1 x B x E\n",
    "\t\tout, (hidden, cell) = self.rnn(e, (hidden, cell))\n",
    "\t\t# out: 1 x B x H\n",
    "\t\tpred = self.fc(out)\n",
    "\t\t# pred: 1 x B x V -> B x V_out\n",
    "\t\treturn pred.squeeze(0), hidden, cell\n",
    "\n",
    "\n",
    "class NMT(nn.Module):\n",
    "\tdef __init__(self, encoder, decoder, target_vocab_size):\n",
    "\t\tsuper(NMT, self).__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.decoder = decoder\n",
    "\t\tself.target_size = target_vocab_size\n",
    "\n",
    "\tdef forward(self, source, target, tch_force=0.9):\n",
    "\t\tbatch_size = source.size(1)\n",
    "\t\ttarget_len = target.size(0)\n",
    "\t\thidden, cell = self.encoder(source)\n",
    "\t\toutputs = torch.zeros(batch_size, target_len,\n",
    "\t\t\t\t\t\t\t  self.target_size).to(device)\n",
    "\n",
    "\t\tx = target[0]\n",
    "\t\tfor t in range(1, target_len):\n",
    "\t\t\toutput, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\t\t\toutputs[:,t, :] = output\n",
    "\t\t\tyhat = output.softmax(1).argmax(1)\n",
    "\t\t\tx = target[t] if random.random() < tch_force else yhat\n",
    "\t\treturn outputs\n",
    "\t\n",
    "\tdef translate(self, source):\n",
    "\t\tbatch_size = source.size(1)\n",
    "\t\ttarget_len = source.size(0) + 2\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\thidden, cell = self.encoder(source)\n",
    "\t\t\toutputs = torch.zeros(batch_size, target_len).to(device)\n",
    "\t\t\tx = source[0,0].unsqueeze(0)\n",
    "\t\t\tfor t in range(1, target_len):\n",
    "\t\t\t\toutput, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\t\t\t\tx = torch.softmax(output, 1).argmax(1)\n",
    "\t\t\t\toutputs[:,t] = x\n",
    "\t\t\t\t# print(english.itos[x.item()])\n",
    "\t\treturn outputs\n",
    "\n",
    "def translate(model, text, source, target, device):\n",
    "\ttext = [source.stoi[word] for word in text.strip().split()]\n",
    "\ttext = torch.tensor(text, dtype=torch.long).unsqueeze(1)\n",
    "\ttext = text.to(device)\n",
    "\tout = model.translate(text).squeeze()\n",
    "\tout = out.cpu().numpy()\n",
    "\tout = [target.itos[idx] for idx in out]\n",
    "\treturn \" \".join(out[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "083f4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params\n",
    "afrikaans = Corpus(f\"{TRAIN_DATA}/afrikaans.txt\", \"Afrikaans\")\n",
    "english = Corpus(f\"{TRAIN_DATA}/english.txt\", \"English\")\n",
    "IN_ENCODER = afrikaans.vocab_size\n",
    "IN_DECODER = english.vocab_size\n",
    "OUT_DECODER = english.vocab_size\n",
    "\n",
    "ENCODER_EMB = 256\n",
    "DECODER_EMB = 256\n",
    "\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 8\n",
    "\n",
    "ENCODER_DRP = 0.5\n",
    "DECODER_DRP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f04f2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(IN_ENCODER, ENCODER_EMB, HIDDEN_SIZE,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "decoder_net = Decoder(IN_DECODER, DECODER_EMB, HIDDEN_SIZE, OUT_DECODER,\n",
    "\t\t\t\t\t  NUM_LAYERS).to(device)\n",
    "nmt = NMT(encoder_net, decoder_net, OUT_DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a7ca3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'effect effect effect effect effect'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"<sos> bereken die <eos>\"\n",
    "translate(nmt, text, afrikaans, english, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee757771",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data = LangData(afrikaans, english)\n",
    "train_loader = dataLoader(train_data, BATCH_SIZE)\n",
    "\n",
    "pad_idx = english.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = optim.NAdam(nmt.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3706000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> <sos> <eos> <eos> <eos> <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 8/8 [00:02<00:00,  2.80batch/s, loss=3.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 8/8 [00:03<00:00,  2.62batch/s, loss=4.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> the the the the the\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 8/8 [00:03<00:00,  2.57batch/s, loss=4.490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> the the <eos> <eos> <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 8/8 [00:03<00:00,  2.55batch/s, loss=4.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> <eos> <eos> <eos> <eos> <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 8/8 [00:03<00:00,  2.55batch/s, loss=4.540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <sos> the the the the the\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:  62%|██████▎   | 5/8 [00:02<00:01,  1.98batch/s, loss=3.336]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(nmt\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/torch/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "# writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "N = len(train_data)\n",
    "text = \"bereken die akkuraatheid van die klassifiseerder\"\n",
    "print(translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "\tpbar = tqdm(train_loader, unit=\"batch\" ,desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\trun_loss = 0\n",
    "\tfor source, target in pbar:\n",
    "\t\tsource = source.to(device)\n",
    "\t\ttarget = target.to(device)\n",
    "\n",
    "\t\toutput = nmt(source, target)\n",
    "\t\toutput = output.reshape(-1, output.shape[2])\n",
    "\t\ttarget = target.reshape(-1)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = criterion(output, target)\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(nmt.parameters(), max_norm=2)\n",
    "\t\toptimizer.step()\n",
    "\t\trun_loss +=loss.item()*source.size(0)\n",
    "\t\tpbar.set_postfix(loss=f\"{run_loss/N:.3f}\")\n",
    "\tprint(translate(nmt, text, afrikaans, english, device)+\"\\n\")\n",
    "\t# writer.add_scalar(\"Training_loss\", run_loss/N, global_step=step)\n",
    "\t# step +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
